#!/usr/bin/env python3
"""
é‡‘ç®¡æœƒæ™ºèƒ½å•ç­”ç³»çµ± - Streamlit éƒ¨ç½²ç‰ˆæœ¬

æ”¯æ´ä¸‰ç¨®è³‡æ–™ä¾†æºï¼š
- è£ç½°æ¡ˆä»¶
- æ³•ä»¤å‡½é‡‹
- é‡è¦å…¬å‘Š
"""

import streamlit as st
import os
import time
from typing import List, Dict, Any

# é é¢é…ç½®
st.set_page_config(
    page_title="é‡‘ç®¡æœƒæ™ºèƒ½å•ç­”",
    page_icon="ğŸ›ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Store é…ç½®
STORES = {
    'penalties': {
        'name': 'fsc-penalties-plaintext',
        'store_id': 'fileSearchStores/fscpenaltiesplaintext-4f87t5uexgui',
        'display_name': 'è£ç½°æ¡ˆä»¶',
        'icon': 'âš–ï¸',
        'description': '490 ç­†é‡‘èæ©Ÿæ§‹è£ç½°æ¡ˆä»¶ (2012-2025)',
        'count': 490,
    },
    'law_interpretations': {
        'name': 'fsc-law-interpretations',
        'store_id': 'fileSearchStores/fsclawinterpretations-zz5pwrly06hz',
        'display_name': 'æ³•ä»¤å‡½é‡‹',
        'icon': 'ğŸ“œ',
        'description': 'æ³•è¦è§£é‡‹ã€ä¿®æ­£èªªæ˜ã€æ¢æ–‡å°ç…§',
        'count': 2872,
    },
    'announcements': {
        'name': 'fsc-announcements',
        'store_id': 'fileSearchStores/fscannouncements-o94q0kmo2zxb',
        'display_name': 'é‡è¦å…¬å‘Š',
        'icon': 'ğŸ“¢',
        'description': 'æ”¿ç­–å…¬å‘Šã€æ³•è¦ä¿®æ­£å…¬å‘Š',
        'count': 1642,
    },
}

# ç¯„ä¾‹å•é¡Œ
EXAMPLE_QUESTIONS = [
    "é•åé‡‘æ§æ³•åˆ©å®³é—œä¿‚äººè¦å®šæœƒå—åˆ°ä»€éº¼è™•ç½°ï¼Ÿ",
    "è«‹å•åœ¨è­‰åˆ¸å› ç‚ºå°ˆæ¥­æŠ•è³‡äººè³‡æ ¼å¯©æ ¸çš„è£ç½°æœ‰å“ªäº›ï¼Ÿ",
    "è¾¦ç†å…±åŒè¡ŒéŠ·è¢«è£ç½°çš„æ¡ˆä¾‹æœ‰å“ªäº›ï¼Ÿ",
    "é‡‘ç®¡æœƒå°å‰µæŠ•å…¬å¸çš„è£ç½°æœ‰å“ªäº›ï¼Ÿ",
    "è­‰åˆ¸å•†é­ä¸»ç®¡æ©Ÿé—œè£ç½°ã€Œè­¦å‘Šã€è™•åˆ†ï¼Œæœ‰å“ªäº›æ¥­å‹™æœƒå—é™åˆ¶ï¼Ÿ",
    "å…§ç·šäº¤æ˜“æœ‰ç½ªåˆ¤æ±ºæ‰€èªå®šé‡å¤§è¨Šæ¯æˆç«‹çš„æ™‚é»",
]


def get_system_prompt(selected_stores: List[str]) -> str:
    """
    æ ¹æ“šé¸å–çš„ Store çµ„åˆç”¢ç”Ÿç³»çµ±æç¤º
    """
    base_prompt = """ä½ æ˜¯å°ˆæ¥­çš„é‡‘èæ³•è¦é¡§å•ã€‚è«‹æ ¹æ“šåƒè€ƒè³‡æ–™å›ç­”å•é¡Œã€‚

å›ç­”æ™‚å¿…é ˆï¼š
1. æ˜ç¢ºå¼•ç”¨ä¾†æºæ–‡ä»¶ï¼ˆæª”æ¡ˆåç¨±ã€æ—¥æœŸï¼‰
2. å¦‚æœè³‡æ–™ä¸­æ²’æœ‰ç›¸é—œè³‡è¨Šï¼Œè«‹èª å¯¦èªªæ˜
3. ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”
4. ä¿æŒå°ˆæ¥­ã€å®¢è§€çš„æ…‹åº¦
"""

    # æ ¹æ“šé¸å–çš„ Store åŠ å…¥ç‰¹å®šæŒ‡å¼•
    specific_guidelines = []

    if 'penalties' in selected_stores:
        specific_guidelines.append("""
ã€è£ç½°æ¡ˆä»¶æŒ‡å¼•ã€‘
- åˆ—èˆ‰å…·é«”æ¡ˆä¾‹èˆ‡è£ç½°å…§å®¹
- èªªæ˜å—ç½°æ©Ÿæ§‹ã€ç½°æ¬¾é‡‘é¡ã€é•è¦è¡Œç‚º
- å¼•ç”¨ç›¸é—œæ³•å¾‹ä¾æ“š""")

    if 'law_interpretations' in selected_stores:
        specific_guidelines.append("""
ã€æ³•ä»¤å‡½é‡‹æŒ‡å¼•ã€‘
- è§£é‡‹æ³•è¦çš„å…·é«”å«ç¾©
- åˆ—å‡ºä¿®æ­£å‰å¾Œçš„å·®ç•°ï¼ˆå¦‚æœ‰ï¼‰
- å¼•ç”¨ç™¼æ–‡å­—è™Ÿ""")

    if 'announcements' in selected_stores:
        specific_guidelines.append("""
ã€é‡è¦å…¬å‘ŠæŒ‡å¼•ã€‘
- èªªæ˜å…¬å‘Šçš„ä¸»è¦å…§å®¹
- åˆ—å‡ºç”Ÿæ•ˆæ—¥æœŸï¼ˆå¦‚æœ‰ï¼‰
- å¼•ç”¨å…¬å‘Šæ–‡è™Ÿ""")

    # çµ„åˆæç¤º
    if specific_guidelines:
        return base_prompt + "\n" + "\n".join(specific_guidelines)
    return base_prompt


def query_gemini(question: str, selected_stores: List[str], api_key: str) -> Dict[str, Any]:
    """
    ä½¿ç”¨ Gemini File Search åŸ·è¡ŒæŸ¥è©¢
    """
    from google import genai
    from google.genai import types

    client = genai.Client(api_key=api_key)

    # å–å¾—é¸å–çš„ Store IDs
    store_ids = [STORES[s]['store_id'] for s in selected_stores if s in STORES]

    if not store_ids:
        return {
            'answer': 'è«‹è‡³å°‘é¸æ“‡ä¸€å€‹è³‡æ–™ä¾†æº',
            'sources': [],
            'error': True
        }

    # å–å¾—ç³»çµ±æç¤º
    system_prompt = get_system_prompt(selected_stores)

    start_time = time.time()

    try:
        # åŸ·è¡ŒæŸ¥è©¢
        response = client.models.generate_content(
            model='gemini-2.5-flash',
            contents=question,
            config=types.GenerateContentConfig(
                tools=[
                    types.Tool(
                        file_search=types.FileSearch(
                            file_search_store_names=store_ids
                        )
                    )
                ],
                temperature=0.1,
                max_output_tokens=2000,
                system_instruction=system_prompt
            )
        )

        latency = time.time() - start_time

        # æå–ç­”æ¡ˆ
        answer = response.text if hasattr(response, 'text') else str(response)

        # æå–ä¾†æº
        sources = extract_sources(response)

        return {
            'answer': answer,
            'sources': sources,
            'latency': latency,
            'error': False
        }

    except Exception as e:
        return {
            'answer': f'æŸ¥è©¢å¤±æ•—: {str(e)}',
            'sources': [],
            'error': True
        }


def extract_sources(response) -> List[Dict[str, Any]]:
    """
    å¾ Gemini å›æ‡‰ä¸­æå–ä¾†æº
    """
    sources = []

    try:
        if hasattr(response, 'candidates') and len(response.candidates) > 0:
            candidate = response.candidates[0]

            if hasattr(candidate, 'grounding_metadata') and candidate.grounding_metadata:
                metadata = candidate.grounding_metadata

                if hasattr(metadata, 'grounding_chunks') and metadata.grounding_chunks:
                    for i, chunk in enumerate(metadata.grounding_chunks):
                        if hasattr(chunk, 'retrieved_context'):
                            context = chunk.retrieved_context

                            # æå–è³‡è¨Š
                            filename = "æœªçŸ¥æ–‡ä»¶"
                            if hasattr(context, 'title') and context.title:
                                filename = context.title
                            elif hasattr(context, 'uri') and context.uri:
                                filename = context.uri.split('/')[-1]

                            snippet = ""
                            if hasattr(context, 'text') and context.text:
                                snippet = context.text[:500]

                            score = 1.0
                            if hasattr(chunk, 'score'):
                                score = float(chunk.score)

                            sources.append({
                                'filename': filename,
                                'snippet': snippet,
                                'score': score,
                            })

    except Exception as e:
        st.warning(f"æå–ä¾†æºæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    return sources


def render_sidebar():
    """æ¸²æŸ“å´é‚Šæ¬„"""
    with st.sidebar:
        st.header("ğŸ“Š è³‡æ–™ä¾†æº")

        # Store é¸æ“‡ï¼ˆå¤šé¸ï¼‰
        selected_stores = []
        for key, store in STORES.items():
            checked = st.checkbox(
                f"{store['icon']} {store['display_name']}",
                value=(key == 'penalties'),  # é è¨­é¸å–è£ç½°æ¡ˆä»¶
                key=f"store_{key}",
                help=store['description']
            )
            if checked:
                selected_stores.append(key)

        st.markdown("---")

        # é¡¯ç¤ºé¸å–çš„è³‡æ–™çµ±è¨ˆ
        if selected_stores:
            total_docs = sum(STORES[s]['count'] for s in selected_stores)
            st.metric("ğŸ“š æ–‡ä»¶ç¸½æ•¸", f"{total_docs:,}")

            with st.expander("â„¹ï¸ è³‡æ–™èªªæ˜", expanded=False):
                for key in selected_stores:
                    store = STORES[key]
                    st.caption(f"{store['icon']} **{store['display_name']}**")
                    st.caption(f"  {store['description']}")
                    st.caption(f"  å…± {store['count']:,} ç­†")
        else:
            st.warning("è«‹è‡³å°‘é¸æ“‡ä¸€å€‹è³‡æ–™ä¾†æº")

        st.markdown("---")

        # ä½¿ç”¨èªªæ˜
        with st.expander("ğŸ’¡ ä½¿ç”¨èªªæ˜", expanded=False):
            st.markdown("""
            **å¦‚ä½•ä½¿ç”¨ï¼š**
            1. åœ¨å·¦å´é¸æ“‡è¦æŸ¥è©¢çš„è³‡æ–™ä¾†æº
            2. è¼¸å…¥æ‚¨çš„å•é¡Œ
            3. é»æ“Šã€ŒæŸ¥è©¢ã€æŒ‰éˆ•
            4. æŸ¥çœ‹ AI ç”Ÿæˆçš„ç­”æ¡ˆå’Œåƒè€ƒä¾†æº

            **è³‡æ–™ä¾†æºèªªæ˜ï¼š**
            - **è£ç½°æ¡ˆä»¶**ï¼šé‡‘èæ©Ÿæ§‹é•è¦è£ç½°è¨˜éŒ„
            - **æ³•ä»¤å‡½é‡‹**ï¼šæ³•è¦è§£é‡‹å’Œä¿®æ­£èªªæ˜
            - **é‡è¦å…¬å‘Š**ï¼šé‡‘ç®¡æœƒæ”¿ç­–å…¬å‘Š
            """)

        st.markdown("---")
        st.caption("ğŸ¤– AI æ™ºèƒ½å•ç­”ç³»çµ±")
        st.caption("âš ï¸ æœ¬ç³»çµ±åƒ…ä¾›åƒè€ƒ")

    return selected_stores


def main():
    """ä¸»ç¨‹å¼"""
    # å–å¾— API Key
    api_key = st.secrets.get("GEMINI_API_KEY") or os.getenv("GEMINI_API_KEY")

    if not api_key:
        st.error("è«‹è¨­å®š GEMINI_API_KEY")
        st.stop()

    # æ¸²æŸ“å´é‚Šæ¬„
    selected_stores = render_sidebar()

    # ä¸»æ¨™é¡Œ
    st.title("ğŸ›ï¸ é‡‘ç®¡æœƒæ™ºèƒ½å•ç­”")
    st.caption("ğŸ’¡ æœ¬ç³»çµ±ç‚ºå±•ç¤ºç”¨ï¼Œå¦‚é‡ç•«é¢ç„¡åæ‡‰ï¼Œè«‹é‡æ–°æ•´ç†é é¢")

    # å•é¡Œè¼¸å…¥
    if 'current_question' not in st.session_state:
        st.session_state.current_question = ""

    question = st.text_area(
        "è«‹è¼¸å…¥æ‚¨çš„å•é¡Œï¼š",
        value=st.session_state.current_question,
        placeholder="ä¾‹å¦‚ï¼šå“ªäº›éŠ€è¡Œå› ç‚ºç†å°ˆæŒªç”¨å®¢æˆ¶æ¬¾é …è¢«è£ç½°ï¼Ÿ",
        height=100
    )

    # æ›´æ–° session state
    if question != st.session_state.current_question:
        st.session_state.current_question = question

    # æŒ‰éˆ•åˆ—
    col1, col2, col3 = st.columns([1, 1, 4])

    with col1:
        submit_button = st.button("ğŸ” æŸ¥è©¢", type="primary", use_container_width=True)

    with col2:
        if st.button("ğŸ—‘ï¸ æ¸…é™¤", use_container_width=True):
            st.session_state.current_question = ""
            st.rerun()

    # è™•ç†æŸ¥è©¢
    if submit_button and question:
        if not selected_stores:
            st.error("è«‹è‡³å°‘é¸æ“‡ä¸€å€‹è³‡æ–™ä¾†æº")
        else:
            with st.spinner("ğŸ” AI æŸ¥è©¢ä¸­..."):
                result = query_gemini(question, selected_stores, api_key)

            if result['error']:
                st.error(result['answer'])
            else:
                # é¡¯ç¤ºçµæœ
                st.success("âœ… æŸ¥è©¢å®Œæˆ")

                # æŒ‡æ¨™æ¬„
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("â±ï¸ å›æ‡‰æ™‚é–“", f"{result['latency']:.2f} ç§’")
                with col2:
                    st.metric("ğŸ“š ä¾†æºæ•¸é‡", len(result['sources']))
                with col3:
                    stores_text = ", ".join([STORES[s]['display_name'] for s in selected_stores])
                    st.metric("ğŸ“‚ æŸ¥è©¢ç¯„åœ", stores_text[:20])

                st.markdown("---")

                # ç­”æ¡ˆ
                st.subheader("ğŸ“ ç­”æ¡ˆ")
                st.markdown(result['answer'])

                st.markdown("---")

                # ä¾†æº
                if result['sources']:
                    st.subheader(f"ğŸ“š åƒè€ƒä¾†æº ({len(result['sources'])} ç­†)")

                    for i, source in enumerate(result['sources'], 1):
                        with st.expander(
                            f"ä¾†æº {i}: {source['filename'][:60]}...",
                            expanded=False
                        ):
                            st.markdown(f"**ç›¸é—œå…§å®¹ï¼š**")
                            st.markdown(f"> {source['snippet'][:300]}...")

                            if source['score'] < 1.0:
                                st.caption(f"ç›¸ä¼¼åº¦: {source['score']:.2%}")
                else:
                    # sources=0 è‡ªå‹•é‡è©¦
                    st.warning("âš ï¸ æœªæ‰¾åˆ°åƒè€ƒä¾†æºï¼Œæ­£åœ¨é‡è©¦...")
                    with st.spinner("é‡æ–°æŸ¥è©¢ä¸­..."):
                        result2 = query_gemini(question, selected_stores, api_key)

                    if result2['sources']:
                        st.success("âœ… é‡è©¦æˆåŠŸ")
                        st.markdown(result2['answer'])

                        for i, source in enumerate(result2['sources'], 1):
                            with st.expander(f"ä¾†æº {i}: {source['filename'][:60]}..."):
                                st.markdown(f"> {source['snippet'][:300]}...")
                    else:
                        st.info("ä½ æŸ¥è©¢çš„å•é¡Œåœ¨ç›®å‰çš„æ–‡ä»¶åº«ä¸­æ²’æœ‰åˆé©çš„çµæœï¼Œè«‹å˜—è©¦æ›å€‹æ–¹å¼æè¿°æ‚¨çš„å•é¡Œã€‚")

    # ç¯„ä¾‹å•é¡Œ
    if not question:
        st.markdown("---")
        st.subheader("ğŸ’¡ ç¯„ä¾‹å•é¡Œ")

        cols = st.columns(2)
        for idx, eq in enumerate(EXAMPLE_QUESTIONS):
            col = cols[idx % 2]
            with col:
                if st.button(f"ğŸ“Œ {eq}", key=f"example_{idx}", use_container_width=True):
                    st.session_state.current_question = eq
                    st.rerun()


if __name__ == "__main__":
    main()
